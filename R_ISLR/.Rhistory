plot(Accept / Apps, S.F.Ratio)
load("/Users/nathaniellai/Desktop/R_Notes/R_ISLR/ISLR_data/Auto.rda")
load("/Users/nathaniellai/Desktop/R_Notes/R_ISLR/ISLR_data/College.rda")
View(College)
# iv.
Elite <- rep("No", nrow(College))
Elite[College$Top10perc>50] <- "Yes"
College <- data.frame(College, Elite)
summary(College)  # 78 Elite
boxplot(College$Outstate~College$Elite, data=College, xlab="Elite", ylab="Outstate")
ggplot(data = College, mapping = aes(x = Accept/Apps, y = S.F.Ratio, color = Elite)) +
geom_point()
#plot(Accept / Apps, S.F.Ratio)
# Colleges with low acceptance rate tend to have low Student-to-faculty ratio.
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate)) +
geom_jitter(mapping = aes(x=Top10perc, y=Grad.Rate), width = 0.6, height = 0.6)
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate, color = Elite)) +
geom_jitter(width = 0.6, height = 0.6)
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate, color = Elite)) +
geom_jitter(mapping = aes(x=Top10perc, y=Grad.Rate), width = 0.6, height = 0.6)
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate, color = Elite)) +
geom_jitter(mapping = aes(x=Top10perc, y=Grad.Rate, color = Elite), width = 0.6, height = 0.6)
# these steps were already taken on College data in the ISLR package
rownames(College) <- College[,1]  # set row names
# iv.
Elite <- rep("No", nrow(College))
Elite[Top10perc>50] <- "Yes"
College <- data.frame(College, Elite)
summary(College)  # 78 Elite
boxplot(Outstate~Elite, data=College, xlab="Elite", ylab="Outstate")
boxplot(Outstate~Private, data=College, xlab="Private", ylab="Outstate")
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate, color = Private)) +
geom_jitter(mapping = aes(x=Top10perc, y=Grad.Rate, color = Private), width = 0.6, height = 0.6)
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate, color = Private, alpha= 0.6)) +
geom_jitter(mapping = aes(x=Top10perc, y=Grad.Rate, color = Private), width = 0.6, height = 0.6)
ggplot(data = College) +
geom_point(mapping = aes(x=Top10perc, y=Grad.Rate, color = Private, alpha= 0.8)) +
geom_jitter(mapping = aes(x=Top10perc, y=Grad.Rate, color = Private), width = 0.6, height = 0.6)
ggplot(data = College, mapping = aes(x = Accept/Apps, y = S.F.Ratio, color = Elite, alpha= 0.8)) +
geom_point()
#plot(Accept / Apps, S.F.Ratio)
# Colleges with low acceptance rate tend to have low Student-to-faculty ratio.
knitr::opts_chunk$set(echo = TRUE)
Auto = read.csv("/Users/nathaniellai/Desktop/R_Notes/R_ISLR/ISLR_data/Auto.csv", header=T, na.strings="?")
Auto = na.omit(Auto)
pairs(Auto[,-9])
cor(subset(Auto, select=-name))
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
summary(lm.fit0)
View(Auto)
Auto = read.csv("~Desktop/R_Notes/R_ISLR/ISLR_data/Auto.csv", header=T, na.strings="?")
Auto = read.csv("~/Desktop/R_Notes/R_ISLR/ISLR_data/Auto.csv", header=T, na.strings="?")
Auto = na.omit(Auto)
pairs(Auto[,-9])
cor(subset(Auto, select=-name))
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
summary(lm.fit0)
par(mfrow=c(2,2))
plot(lm.fit0)
plot(predict(lm.fit0), rstudent(lm.fit0))
plot(predict(lm.fit0), rstudent(lm.fit0), ylab = 'Standized Residuals', xlab = 'Fitted values')
abline(0, 3)
plot(predict(lm.fit0), rstudent(lm.fit0), pch = 20, ylab = 'Standized Residuals', xlab = 'Fitted values')
abline(0, 3)
plot(predict(lm.fit0), rstudent(lm.fit0), pch = 20, alpha = 0.7, ylab = 'Standized Residuals', xlab = 'Fitted values')
abline(0, 3)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(0, 3)
# Interaction Terms
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
lm.fit1 <- lm(mpg~cylinders+weight*cylinders+year+origin, data=Auto)
lm.fit2 <- lm(mpg~acceleration+weight*acceleration+year+origin, data=Auto)
lm.fit3 <- lm(mpg~horsepower+weight*horsepower+year+origin, data=Auto)
summary(lm.fit0)
summary(lm.fit1)
summary(lm.fit2)
summary(lm.fit3)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(0, 3)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
ylab = 'Standized Residuals')
abline(0, 3)
abline(3,0)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3,0)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3,0)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3,0 linetype = 4)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3,0 type="l", lty=2)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3, 0, type="l", lty=2)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3, 0, type="l", lty=2)
# Interaction Terms
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
# lm.fit1 <- lm(mpg~cylinders+weight*cylinders+year+origin, data=Auto)
# lm.fit2 <- lm(mpg~acceleration+weight*acceleration+year+origin, data=Auto)
# lm.fit3 <- lm(mpg~horsepower+weight*horsepower+year+origin, data=Auto)
summary(lm.fit0)
# summary(lm.fit1)
# summary(lm.fit2)
# summary(lm.fit3)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4))
# Non-linear Transformations of the Predictors
lm.fit4<-lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit4)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4))
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4))
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4)
pch = 20,
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, type="l", lty=2)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, type="l", lty=2)
lm.fit = lm(y~x)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, type="l", lty=2)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, type="l", lty=2)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
# Non-linear Transformations of the Predictors
lm.fit4<-lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit4)
?abline
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3, 0, lty=2)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3, 0, lty=2)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, lty=2)
lm.fit = lm(y~x)
set.seed (1)
x=rnorm (100)
y=2*x+rnorm (100)
plot(x,y)
# Regress y on x. Result is highly significant
lm.fit0 <- lm(y~x+0)
summary(lm.fit0)
# Regress x on y. Result is highly significant
lm.fit1 <- lm(x~y+0)
summary(lm.fit1)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
# Question 11a is the example in point.
set.seed (1)
x=rnorm (100)
y=2*x+rnorm (100)
plot(x,y)
# Regress y on x. Result is highly significant
lm.fit0 <- lm(y~x+0)
summary(lm.fit0)
# Regress x on y. Result is highly significant
lm.fit1 <- lm(x~y+0)
summary(lm.fit1)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
set.seed(1)
x <- rnorm(100)
# Generate random sample (i.e. y ) from x without replacement
y <- -sample(x, 100)
# suh that:
sum(x^2)==sum(y^2)
lm.fit_x <- lm(y~x+0)
lm.fit_y <- lm(x~y+0)
summary(lm.fit_x)
summary(lm.fit_y)
set.seed (1)
x1=runif (100)
x2 =0.5*x1+rnorm (100) /10
y=2+2*x1 +0.3*x2+rnorm (100)
cor(x1,x2)
plot(x1,x2)
lm.fit <- lm(y~x1+x2)
summary(lm.fit)
par(mfrow=c(2,1), mar=c(2, 3, 2, 1), mgp=c(2, 0.8, 0))
lm.fit1 <- lm(y~x1)
summary(lm.fit1)
plot(x1,y)
abline(lm.fit1)
lm.fit2 <- lm(y~x2)
summary(lm.fit2)
plot(x2,y)
abline(lm.fit2)
x1=c(x1, 0.1)
x2=c(x2, 0.8)
y=c(y,6)
par(mfrow=c(2,2), mar=c(3.5, 3.5, 2, 1), mgp=c(2.4, 0.8, 0))
# regression with both x1 and x2
fit.lm <- lm(y~x1+x2)
summary(fit.lm)
plot(fit.lm)
# regression with x1 only
fit.lm1 <- lm(y~x2)
summary(fit.lm1)
plot(fit.lm1)
# regression with x2 only
fit.lm2 <- lm(y~x1)
summary(fit.lm2)
plot(fit.lm2)
lm.fit = lm(y~x)
set.seed (1)
x=rnorm (100)
y=2*x+rnorm (100)
plot(x,y)
# Regress y on x. Result is highly significant
lm.fit0 <- lm(y~x+0)
summary(lm.fit0)
# Regress x on y. Result is highly significant
lm.fit1 <- lm(x~y+0)
summary(lm.fit1)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
set.seed (1)
x=rnorm (100)
y=2*x+rnorm (100)
plot(x,y)
# Regress y on x. Result is highly significant
lm.fit0 <- lm(y~x+0)
summary(lm.fit0)
# Regress x on y. Result is highly significant
lm.fit1 <- lm(x~y+0)
summary(lm.fit1)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
par(mfrow=c(2,1), mar=c(2, 3, 2, 1), mgp=c(2, 0.8, 0))
lm.fit1 <- lm(y~x1)
# Non-linear Transformations of the Predictors
lm.fit4 <- lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit4)
par(mfrow=c(2,2))
plot(lm.fit4)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, lty=2)
# Non-linear Transformations of the Predictors
lm.fit4 <- lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit4)
par(mfrow=c(2,2))
plot(lm.fit4)
par(mfrow=c(2,2))
plot(lm.fit0)
set.seed (1)
x1=runif (100)
x2 =0.5*x1+rnorm (100) /10
y=2+2*x1 +0.3*x2+rnorm (100)
cor(x1,x2)
plot(x1,x2)
lm.fit <- lm(y~x1+x2)
summary(lm.fit)
cor(x1,x2)
plot(x1,x2, xlab = x1, ylab = x2)
lm.fit <- lm(y~x1+x2)
summary(lm.fit)
cor(x1,x2)
plot(x1,x2, xlab = 'x1', ylab = 'x2')
lm.fit <- lm(y~x1+x2)
summary(lm.fit)
set.seed (1)
x1=runif (100)
x2 =0.5*x1+rnorm (100) /10
y=2+2*x1 +0.3*x2+rnorm (100)
cor(x1,x2)
plot(x1,x2, xlab = 'x1', ylab = 'x2')
lm.fit <- lm(y~x1+x2)
summary(lm.fit)
par(mfrow=c(2,1), mar=c(2, 3, 2, 1), mgp=c(2, 0.8, 0))
lm.fit1 <- lm(y~x1)
summary(lm.fit1)
plot(x1,y)
abline(lm.fit1)
lm.fit2 <- lm(y~x2)
summary(lm.fit2)
plot(x2,y)
abline(lm.fit2)
par(mfrow=c(2,1), mar=c(2, 3, 2, 1), mgp=c(2, 0.8, 0))
lm.fit1 <- lm(y~x1)
summary(lm.fit1)
plot(x1,y,xlab = 'x1')
abline(lm.fit1)
lm.fit2 <- lm(y~x2)
summary(lm.fit2)
plot(x2,y, xlab = 'x2')
abline(lm.fit2)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
cex = 0.8,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
par(mfrow=c(2,2))
plot(lm.fit0)
Auto = read.csv("~/Desktop/R_Notes/R_ISLR/ISLR_data/Auto.csv", header=T, na.strings="?")
Auto = na.omit(Auto)
pairs(Auto[,-9])
cor(subset(Auto, select=-name))
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
summary(lm.fit0)
par(mfrow=c(2,2))
plot(lm.fit0)
# Interaction Terms
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
lm.fit1 <- lm(mpg~cylinders+weight*cylinders+year+origin, data=Auto)
# lm.fit2 <- lm(mpg~acceleration+weight*acceleration+year+origin, data=Auto)
# lm.fit3 <- lm(mpg~horsepower+weight*horsepower+year+origin, data=Auto)
summary(lm.fit0)
summary(lm.fit1)
# summary(lm.fit2)
# summary(lm.fit3)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
cex = 0.8,a
xlab = 'Fitted values',
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20,
cex = 0.8,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3, 0, lty=2)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20, cex = 0.9,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, lty=2)
reprex:::reprex_addin()
reprex:::reprex_addin()
install.packages("shinyjs")
knitr::opts_chunk$set(echo = TRUE)
Auto = read.csv("~/Desktop/R_Notes/R_ISLR/ISLR_data/Auto.csv", header=T, na.strings="?")
Auto = na.omit(Auto)
pairs(Auto[,-9])
cor(subset(Auto, select=-name))
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
summary(lm.fit0)
par(mfrow=c(2,2))
plot(lm.fit0)
plot(predict(lm.fit0), rstudent(lm.fit0),
pch = 20, cex = 0.8,
xlab = 'Fitted values',
ylab = 'Standized Residuals')
abline(3, 0, lty=2)
# Interaction Terms
lm.fit0 <- lm(mpg ~ . -name, data=Auto)
lm.fit1 <- lm(mpg~cylinders+weight*cylinders+year+origin, data=Auto)
# lm.fit2 <- lm(mpg~acceleration+weight*acceleration+year+origin, data=Auto)
# lm.fit3 <- lm(mpg~horsepower+weight*horsepower+year+origin, data=Auto)
summary(lm.fit0)
summary(lm.fit1)
# summary(lm.fit2)
# summary(lm.fit3)
# Non-linear Transformations of the Predictors
lm.fit4 <- lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit4)
par(mfrow=c(2,2))
plot(lm.fit4)
par(mfrow=c(1,1))
plot(predict(lm.fit4),rstudent(lm.fit4), pch = 20, cex = 0.8,
xlab = 'Fitted values',
ylab = 'Standized Residuals',
ylim = c(-3, 4))
abline(3, 0, lty=2)
set.seed (1)
x=rnorm (100)
y=2*x+rnorm (100)
plot(x,y, cex=0.8)
# Regress y on x. Result is highly significant
lm.fit0 <- lm(y~x+0)
summary(lm.fit0)
# Regress x on y. Result is highly significant
lm.fit1 <- lm(x~y+0)
summary(lm.fit1)
lm.fit = lm(y~x)
lm.fit2 = lm(x~y)
summary(lm.fit)
summary(lm.fit2)
# Question 11a is the example in point.
set.seed(1)
x <- rnorm(100)
# Generate random sample (i.e. y ) from x without replacement
y <- -sample(x, 100)
# suh that:
sum(x^2)==sum(y^2)
lm.fit_x <- lm(y~x+0)
lm.fit_y <- lm(x~y+0)
summary(lm.fit_x)
summary(lm.fit_y)
set.seed (1)
x1=runif (100)
x2 =0.5*x1+rnorm (100) /10
y=2+2*x1 +0.3*x2+rnorm (100)
cor(x1,x2)
plot(x1,x2, xlab = 'x1', ylab = 'x2', cex=0.8)
lm.fit <- lm(y~x1+x2)
summary(lm.fit)
par(mfrow=c(2,1), mar=c(2, 3, 2, 1), mgp=c(2, 0.8, 0))
lm.fit1 <- lm(y~x1)
summary(lm.fit1)
plot(x1,y, cex=0.8)
abline(lm.fit1)
lm.fit2 <- lm(y~x2)
summary(lm.fit2)
plot(x2,y, cex=0.8)
abline(lm.fit2)
x1=c(x1, 0.1)
x2=c(x2, 0.8)
y=c(y,6)
par(mfrow=c(2,2), mar=c(3.5, 3.5, 2, 1), mgp=c(2.4, 0.8, 0))
# regression with both x1 and x2
fit.lm <- lm(y~x1+x2)
summary(fit.lm)
plot(fit.lm)
# regression with x1 only
fit.lm1 <- lm(y~x2)
summary(fit.lm1)
plot(fit.lm1)
# regression with x2 only
fit.lm2 <- lm(y~x1)
summary(fit.lm2)
plot(fit.lm2)
